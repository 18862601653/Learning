# Membership Inference Attacks Against Machine Learning Models

## 论文概述


## 部分记录

攻击黑盒模型（由商业界建立的“machine learning as a service”）比攻击白盒模型复杂，因为白盒模型的结构和参数对于攻击者来说是已知的。

为了构建攻击模型，本文提出了shadow training技术：首先，创建多个“shadow models”用来模仿目标模型的行为，但是训练的数据集和ground truth是已知的，然后用标记的影子模型的输入和输出训练攻击模型。

为影子模型生成训练数据的有效方法：
  - 使用黑盒模型访问目标模型来合成数据（不假设任何关于目标模型训练数据分布的先验知识）
  - 统计来自目标训练数据集绘制的总体（在推断一个给定记录是否在训练数据集中之前，允许攻击者查询目标模型一次)
  - 假设攻击者可以访问有噪音的目标训练数据集版本（在推断一个给定记录是否在训练数据集中之前，允许攻击者查询目标模型一次)






























## 知识点
- membership inference
  给定一个机器学习模型和一条记录，确定这条记录是否是模型的训练集中的一部分。
- 机器学习算法
  无监督的训练模型目标是从未标记的数据中提取有用的性质，并建立一个可以解释它的隐藏结构的模型；有监督的训练模型的训练集被打了标签，目的是学习数据和标签之间的关系，并构造一个模型使其适用于一般数据。
  
  模型训练算法的目的是最小化模型在训练数据集上的预测错误，但是这可能会导致过拟合，即对训练样本预测效果很好，但是对测试样本预测效果很差。所以正则化技术被提出来防止过拟合同时还最小化预测错误。
  
  有监督的训练常用于分类和其他预测任务。
  
- Machine learning as a service
  主流的互联网公司在他们的云服务平台上提供了机器学习服务，如Google Prediction API，Amazon Machine Learning、Microsoft Azure Machine Learning以及BigML。这些平台提供上传数据以及训练和查询模型的简单的API。
  
  模型和训练算法的细节对数据拥有者不可见，服务提供者基本不提供正则化，所以可能导致过拟合。模型不能下载，只能通过服务API访问，因而称之为黑盒。
  
- 模型反演中关于隐私的概念：如果一个敌人可以使用模型的输出来推断作为模型输入的非预期（敏感）属性的值，就会发生隐私泄露。




















